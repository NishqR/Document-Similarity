{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1341ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from time import time\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "#stop_words = stopwords.words('english')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def preprocess(sentence):\n",
    "    return [w for w in sentence.lower().split() if w not in stop_words]\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    run_relevant = True\n",
    "    main_start = time() \n",
    "\n",
    "    #articles_df = pd.read_csv(\"all_articles.csv\")\n",
    "    articles_df = pd.read_csv(\"labelled_1.csv\")\n",
    "    articles_df.fillna(\"\", inplace=True)\n",
    "\n",
    "    num_runs = 0\n",
    "\n",
    "    while(num_runs < 2):\n",
    "        \n",
    "        count_dict = {}\n",
    "\n",
    "\n",
    "        if run_relevant == True:\n",
    "\n",
    "            articles = list(articles_df[articles_df['relevant'] == 1]['text'])\n",
    "\n",
    "        else:\n",
    "\n",
    "            articles = list(articles_df[articles_df['relevant'] == 0]['text'])      \n",
    "\n",
    "        #print(sorted(((v, k) for k, v in count_dict.items()), reverse=True))\n",
    "        \n",
    "        for article in articles:\n",
    "        \n",
    "        #start = time()\n",
    "        \n",
    "            sentences = sent_tokenize(article)\n",
    "            \n",
    "            for sentence in sentences:\n",
    "                words_in_sentence = list(sentence.split(\" \"))\n",
    "                for word_ in words_in_sentence:\n",
    "\n",
    "                    word_ = word_.lower()\n",
    "                    word_ = word_.strip()\n",
    "                    word_ = word_.replace(\" \", \"\")\n",
    "                    word_ = word_.replace(\",\", \"\")\n",
    "                    word_ = word_.replace(\".\", \"\")\n",
    "                    word_ = word_.replace(\":\", \"\")\n",
    "                    word_ = word_.replace(\"/\", \"\")\n",
    "                    word_ = word_.replace(\"-\", \"\")\n",
    "                    word_ = word_.replace(\"(\", \"\")\n",
    "                    word_ = word_.replace(\")\", \"\")\n",
    "\n",
    "                    if lemmatizer.lemmatize(word_) != 'ha' and lemmatizer.lemmatize(word_) != 'wa':\n",
    "                        word_ = lemmatizer.lemmatize(word_)\n",
    "\n",
    "                    if word_ not in stop_words and word_ not in string.punctuation:\n",
    "                        if word_ not in count_dict.keys():\n",
    "                            #embeddings_dict[word_] = model.encode(word_)\n",
    "                            #embeddings_dict[word_] = \"\"\n",
    "                            count_dict[word_] = 1\n",
    "\n",
    "                        else:\n",
    "                            count_dict[word_] += 1\n",
    "\n",
    "            #count[0]+=1\n",
    "            #print('Cell took %.2f seconds to run.' % (time() - start))\n",
    "\n",
    "        if run_relevant == True:\n",
    "            relevant_df = pd.DataFrame(pd.Series(count_dict), columns = ['frequency'])\n",
    "            relevant_df.reset_index(inplace=True)\n",
    "            relevant_df = relevant_df.rename(columns={'index': 'word'})\n",
    "            relevant_df = relevant_df.sort_values(by=['frequency'], ascending=False)\n",
    "            \n",
    "            # apply normalization techniques\n",
    "            apply_scale_column = 'frequency'\n",
    "            relevant_df['frequency_scaled'] = MinMaxScaler().fit_transform(np.array(relevant_df[apply_scale_column]).reshape(-1,1))\n",
    "              \n",
    "            relevant_df.to_csv(\"relevant_words_count.csv\")\n",
    "            \n",
    "        else:\n",
    "            irrelevant_df = pd.DataFrame(pd.Series(count_dict), columns = ['frequency'])\n",
    "            irrelevant_df.reset_index(inplace=True)\n",
    "            irrelevant_df = irrelevant_df.rename(columns={'index': 'word'})\n",
    "            irrelevant_df = irrelevant_df.sort_values(by=['frequency'], ascending=False)\n",
    "            \n",
    "            # apply normalization techniques\n",
    "            apply_scale_column = 'frequency'\n",
    "            irrelevant_df['frequency_scaled'] = MinMaxScaler().fit_transform(np.array(irrelevant_df[apply_scale_column]).reshape(-1,1))\n",
    "            \n",
    "            irrelevant_df.to_csv(\"irrelevant_words_count.csv\")\n",
    "        \n",
    "        num_runs += 1\n",
    "        run_relevant = False\n",
    "\n",
    "    num_words_relevant = 70\n",
    "    num_words_irrelevant = 70\n",
    "\n",
    "    relevant_words = list(relevant_df.head(num_words_relevant).word)\n",
    "    irrelevant_words = list(irrelevant_df.head(num_words_irrelevant).word)\n",
    "    common_words = intersection(relevant_words, irrelevant_words)\n",
    "    \n",
    "    unique_relevant = [x for x in relevant_words if x not in common_words]\n",
    "    unique_irrelevant = [x for x in irrelevant_words if x not in common_words]\n",
    "\n",
    "    print(\"COMMON WORDS\")\n",
    "    print(common_words)\n",
    "    \n",
    "    print(\"UNIQUE RELEVANT\")\n",
    "    print(unique_relevant)\n",
    "\n",
    "    print(\"UNIQUE IRRELEVANT\")\n",
    "    print(unique_irrelevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "849b84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(pd.Series(count_dict), columns = ['frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9152583",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff8b4175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>senator</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>reverend</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>warnock</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>introduces</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bill</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>honeymoon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>pact</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5389</th>\n",
       "      <td>inspired</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>sea</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>million?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5392 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  frequency\n",
       "0        senator         13\n",
       "1       reverend          5\n",
       "2        warnock          9\n",
       "3     introduces          1\n",
       "4           bill         33\n",
       "...          ...        ...\n",
       "5387   honeymoon          1\n",
       "5388        pact          1\n",
       "5389    inspired          1\n",
       "5390         sea          1\n",
       "5391    million?          1\n",
       "\n",
       "[5392 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df = output_df.rename(columns={'index': 'word'})\n",
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d19f4cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['senator',\n",
       " 'reverend',\n",
       " 'warnock',\n",
       " 'introduces',\n",
       " 'bill',\n",
       " 'ensure',\n",
       " 'georgia',\n",
       " 'car',\n",
       " 'buyer',\n",
       " 'automaker',\n",
       " 'fully',\n",
       " 'benefit',\n",
       " 'cost-cutting',\n",
       " 'tax',\n",
       " 'credits;',\n",
       " 'today',\n",
       " 'introduced',\n",
       " 'affordable',\n",
       " 'electric',\n",
       " 'vehicle',\n",
       " 'america',\n",
       " 'act',\n",
       " 'would',\n",
       " 'create',\n",
       " 'phase-in',\n",
       " 'period',\n",
       " '(ev)',\n",
       " 'sourcing',\n",
       " 'manufacturing',\n",
       " 'requirement']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(output_df.head(30).word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cef04bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pension', 'said', 'retirement', 'year', 'loan', 'mortgage', 'money',\n",
       "       'rate', 'student', 'pay', 'ha', 'people', 'plan', 'tax', 'debt', 'also',\n",
       "       'per', 'say', 'financial', 'new'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(output_df.sort_values(by=[0], ascending=False).head(20).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9307e8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7775219a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
